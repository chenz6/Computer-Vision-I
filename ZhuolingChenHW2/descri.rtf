{\rtf1\ansi\ansicpg1252\cocoartf1671
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 # Initiate SIFT detector\
os.environ["CUDA_VISIBLE_DEVICES"] = "1"\
\
sift = cv2.xfeatures2d.SIFT_create(30)\
surf = cv2.xfeatures2d.SURF_create(30)\
#surf.hessianThreshold = 30\
\
\
\
def getPatches(kps, img, size=32, num=500):\
    res = torch.zeros(num, 1, size, size)\
    if type(img) is np.ndarray:\
        img = torch.from_numpy(img)\
    h, w = img.shape      # note: for image, the x direction is the verticle, y-direction is the horizontal...\
    for i in range(num):\
        cx, cy = kps[i]\
        cx, cy = int(cx), int(cy)\
        dd = int(size/2)\
        xmin, xmax = max(0, cx - dd), min(w, cx + dd ) - 1\
        ymin, ymax = max(0, cy - dd), min(h, cy + dd ) - 1 \
        \
        xmin_res, xmax_res = dd - min(dd,cx), dd + min(dd, w - cx)-1\
        ymin_res, ymax_res = dd - min(dd,cy), dd + min(dd, h - cy)-1\
\
        res[i, 0, ymin_res: ymax_res, xmin_res: xmax_res] = img[ymin: ymax, xmin: xmax]\
    return res\
\
\
img_dir = "query"\
kps_num = 30\
patch_size = 32\
res = torch.zeros(35, kps_num, 2)\
patches = torch.zeros(35, kps_num, 1, patch_size, patch_size)\
if os.path.exists(img_dir):\
    if os.listdir(img_dir) is []:\
        print("No images!")\
        exit(0)\
    num_img = len(os.listdir(img_dir))\
    idx = 0\
   \
 #     #for img in os.listdir(img_dir):\
\
#         if not img.endswith("JPG"):\
#             continue\
    for i in range(1,36):\
        img = "q"+str(i) + ".JPG"\
           \
            \
        image_dir = os.path.join(img_dir, img)\
        image = cv2.imread(image_dir)\
        img= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\
       \
      \
        ## find the keypoints and descriptors with SIFT\
        kps, des = sift.detectAndCompute(img, None)\
        \
        if (len(kps)) < 30:\
            kps, des = surf.detectAndCompute(img,None)\
            \
        keypoints_img = [kps[a].pt for a in range(kps_num)] \
        res[idx] = torch.FloatTensor(keypoints_img)\
        \
#         print(image_dir)\
        ## extract patches\
        patches[idx] = getPatches(keypoints_img, img, size=patch_size, num=kps_num)\
     \
        #idx += 1\
        \
        ## plot keypoints on each image\
        # img2 = cv2.drawKeypoints(img, kps, None, color=(255,0,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\
        # plt.imshow(img2)\
        # plt.show()\
        \
else:\
    print("image folder not exists!")\
    exit(0)\
\
\
## save tensors\
output_dir_kps = "keypoints.pt"\
output_dir_patches = "patches.pt"\
torch.save(res, output_dir_kps)\
torch.save(patches, output_dir_patches)\
\
test_kps = torch.load(output_dir_kps)\
test_patches = torch.load(output_dir_patches)\
\
\
\
re_patches = torch.zeros(35,30,1,32,32)\
for j in range(35):\
    re_patches[j] = test_patches[j]\
\
from descriptor_CNN3 import DesNet\
\
trained_weight = torch.load("./checkpoint.pth")\
model = DesNet().cuda()         \
model.load_state_dict(trained_weight['state_dict'])\
re_patches = re_patches.view(-1, 1, 32, 32).cuda()\
print(type(re_patches))\
print(re_patches.shape)\
\
#print(model)\
with torch.no_grad():\
    output = model(re_patches)\
\
\
\
out3 = output.view(35, 30, 128).cpu().data\
print(output.size())\
output_dir ='35keypoints.pt'\
torch.save(out3,output_dir)\
\
\
file='140keypoints.pt'\
torch.load("./140keypoints.pt")}